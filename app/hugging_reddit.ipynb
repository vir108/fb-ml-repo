{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import secrets\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models used here from HuggingFace:\n",
    "* [News Classifier](https://huggingface.co/mrm8488/bert-mini-finetuned-age_news-classification)\n",
    "* [Sentiment Analysis Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "news_tokenizer = AutoTokenizer.from_pretrained(config.HF_TOKENIZER_NEWS_CLASSIFIER)\n",
    "news_model = AutoModelForSequenceClassification.from_pretrained(config.HF_MODEL_NEWS_CLASSIFIER)\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=secrets.REDDIT_API_CLIENT_ID,\n",
    "    client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent=secrets.REDDIT_API_USER_AGENT\n",
    ")\n",
    "subreddit = reddit.subreddit(config.NEWS_SUBREDDITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = []\n",
    "\n",
    "# Stream new submissions in from our favorite subreddits until we reach a certain number\n",
    "for submission in subreddit.stream.submissions():\n",
    "    submissions.append(submission)\n",
    "    if len(submissions) > config.NUM_SUBMISSION_TO_GET:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditSubmission():\n",
    "    subreddit: str\n",
    "    title: str\n",
    "    time_created: datetime.datetime\n",
    "    author: str\n",
    "    inference_subject: str\n",
    "    inference_sentiment: str\n",
    "\n",
    "    def __init__(self, subreddit: str, title: str, time_created: str, author: str, inference_subject: str = None, inference_sentiment: str = None):\n",
    "        self.subreddit = subreddit\n",
    "        self.title = title\n",
    "        self.time_created = self.convert_time_to_datetime(time_created)\n",
    "        self.author = author\n",
    "        self.inference_subject = self.run_subject_analysis()\n",
    "        self.inference_sentiment = self.run_sentiment_analysis()\n",
    "\n",
    "    # Convert time from Reddit API into a Python datetime object\n",
    "    def convert_time_to_datetime(self, time_created) -> datetime.datetime:\n",
    "        dt = datetime.datetime.fromtimestamp(time_created)\n",
    "        return dt\n",
    "\n",
    "    # Take the output from our news classifier and map it to a class\n",
    "    def map_news_output_to_class(self, inference_output: torch.Tensor) -> str:\n",
    "        softmax_values = []\n",
    "        for output in inference_output:\n",
    "            softmax_values.append(output.item())\n",
    "        max_value = max(softmax_values)\n",
    "        max_index = softmax_values.index(max_value)\n",
    "        return config.NEWS_CLASSES[max_index]\n",
    "    \n",
    "    # Run the news classifier model on the input\n",
    "    def run_subject_analysis(self) -> str:\n",
    "        inputs = news_tokenizer(self.title, return_tensors=\"pt\")\n",
    "        labels = torch.tensor([1]).unsqueeze(0) # Batch size of 1\n",
    "        outputs = news_model(**inputs, labels=labels) # Unpack key-value pairs into keyword args in function call\n",
    "        news_subject = self.map_news_output_to_class(outputs.logits[0]) # Taking softmax tensor from inference\n",
    "        return news_subject\n",
    "\n",
    "    # Run the sentiment analysis pipeline model on the input\n",
    "    def run_sentiment_analysis(self) -> str:\n",
    "        sentiment = sentiment_model(self.title)\n",
    "        return sentiment[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submission_objects = []\n",
    "\n",
    "# Transform submissions into easy to handle objects\n",
    "for submission in submissions:\n",
    "    s = RedditSubmission(submission.subreddit, submission.title, submission.created_utc, submission.author)\n",
    "    reddit_submission_objects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our scraped data into a Pandas dataframe\n",
    "pd.DataFrame([vars(submission) for submission in reddit_submission_objects])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up:\n",
    "1. How do I find the top 100 posts of all time from your favorite subreddits?\n",
    "2. How do I parse comments from the post?\n",
    "3. And finally, how do I parse replies from that comment?\n",
    "4. Bonus! If you have time, browse HuggingFace and try to find an out of the box model to apply to your favorite Reddit data. Even if you can't code it up, how would you, given enough time, implement the algorithm(s)?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0fafcf4f970cab54a859adb46f4fd24f44b14105ac04ffe0bbdc9768e9518fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('reddit-broker-bot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
